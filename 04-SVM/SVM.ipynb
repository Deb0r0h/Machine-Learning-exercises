{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Regression on House Pricing Dataset with SVM\n",
    "We consider a reduced version of a dataset containing house sale prices for King County, which includes Seattle. It includes homes sold between May 2014 and May 2015.\n",
    "\n",
    "https://www.kaggle.com/harlfoxem/housesalesprediction\n",
    "\n",
    "For each house we know 18 house features (e.g., number of bedrooms, number of bathrooms, etc.) plus its price, that is what we would like to predict."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "\n",
    "In the notebook you will first:\n",
    "- split the data into training, validation, and test\n",
    "- standardize the data\n",
    "\n",
    "You will then be asked to learn various SVM models, in particular:\n",
    "- for each of the kernels ‘linear’, ‘poly’, ‘rbf’, and ‘sigmoid’, you will learn the best model having to choose among various values of some hyperparameters; the choice of hyperparameters must be done with 5-fold cross-validation\n",
    "- choose the best kernel, using a validation approach (not cross-validation)\n",
    "- learn the best SVM model overall\n",
    "\n",
    "You will then be asked to estimate the generalization error of the best SVM model you report. \n",
    "\n",
    "At the end, just for comparison, you will alsk be asked to learn a standard linear regression model (with squared loss), and estimate its generalization error.\n",
    "\n",
    "### IMPORTANT\n",
    "- Note that in each of the above steps you will have to choose the appropriate split of the data (see the first bullet point above)\n",
    "- The code should run without requiring modifications even if some best choice of parameters, changes; for example, you should not pass the best value of hyperparameters \"manually\" (i.e., passing the values as input parameters to the models). The only exception is in the TO DO titled 'ANSWER THE FOLLOWING'\n",
    "- For SVM, since the values to be predicted are all in the thousands of dollars, you will need to always set epsilon=1000\n",
    "- Do not change the printing instructions (other than adding the correct variable name for your code), and do not add printing instructions!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TO DO - INSERT YOUR NUMERO DI MATRICOLA BELOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#put here your ``numero di matricola''\n",
    "numero_di_matricola = 2095664"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code loads all required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#import all packages needed\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn import svm\n",
    "from sklearn import model_selection\n",
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "The code below loads the data and remove samples with missing values. It also prints the number of samples in the datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of samples: 3164\n"
     ]
    }
   ],
   "source": [
    "#load the data - do not change the path below!\n",
    "df = pd.read_csv('kc_house_data.csv', sep = ',')\n",
    "\n",
    "#remove the data samples with missing values (NaN)\n",
    "df = df.dropna() \n",
    "\n",
    "Data = df.values\n",
    "m = Data.shape[0]\n",
    "Y = Data[:m,2]\n",
    "X = Data[:m,3:]\n",
    "\n",
    "print(\"Total number of samples:\",m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TO DO - SPLIT DATA INTO TRAINING, VALIDATION, AND TESTING, WITH THE FOLLOWING PERCENTAGES: 60%, 20%, 20%\n",
    "\n",
    "Use the train_test_split function from sklearn.model_selection to do it; in every call fix random_state to your numero_di_matricola. At the end, you should store the data in the following variables:\n",
    "- Xtrain, Ytrain: training data\n",
    "- Xval, Yval: validation data\n",
    "- Xtrain_val, Ytrain_val: training and validation data\n",
    "- Xtest, Ytest: test data\n",
    "\n",
    "The code then prints the number of samples in Xtrain, Xval, Xtrain_val, and Xtest\n",
    "\n",
    "IMPORTANT:\n",
    "- first split the data into training+validation and test; the first part of the data in output from train_test_split must correspond to the training+validation\n",
    "- then split training+validation into training and validation; the first part of the data in output from train_test_split must correspond to the training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training size:  1898\n",
      "Validation size:  633\n",
      "Training and validation size: 2531\n",
      "Test size: 633\n"
     ]
    }
   ],
   "source": [
    "Xtrain_val, Xtest, Ytrain_val, Ytest = train_test_split(X, Y, test_size=0.2, random_state=numero_di_matricola)\n",
    "Xtrain, Xval, Ytrain, Yval = train_test_split(Xtrain_val,Ytrain_val,test_size=0.25,random_state=numero_di_matricola)\n",
    "\n",
    "print(\"Training size: \", Xtrain.shape[0])\n",
    "print(\"Validation size: \", Xval.shape[0])\n",
    "print(\"Training and validation size:\",Xtrain_val.shape[0])\n",
    "print(\"Test size:\",Xtest.shape[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TO DO - STANDARDIZE THE DATA\n",
    "\n",
    "Standardize the data using the preprocessing.StandardScaler from scikit learn.\n",
    "\n",
    "If V is the name of the variable storing part of the data, the corresponding standardized version should be stored in V_scaled. For example, the scaled version of Xtrain should be stored in Xtrain_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scaler = preprocessing.StandardScaler()\n",
    "scaler.fit(Xtrain)\n",
    "\n",
    "Xtrain_scaled = scaler.transform(Xtrain)\n",
    "Xval_scaled = scaler.transform(Xval)\n",
    "Xtest_scaled = scaler.transform(Xtest)\n",
    "Xtrain_val_scaled = scaler.transform(Xtrain_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# SVM models: learning the best model for each kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TO DO - CHOOSE THE BEST HYPERPARAMETERS FOR LINEAR KERNEL\n",
    "\n",
    "Consider svm.SVR and linear kernel. Consider the following hyperparameters and their values:\n",
    "- C: 0.1, 1, 10, 100, 1000\n",
    "\n",
    "Leave all other input parameters to default. \n",
    "\n",
    "Find the best value of the hyperparameters using 5-fold cross validation. Use model_selection.GridSearchCV to perform the cross-validation.\n",
    "\n",
    "Print the best value of the hyperparameters (they are in the attribute best_params_ from GridSearchCV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Linear SVM\n",
      "Best value for hyperparameters:  {'C': 1000}\n"
     ]
    }
   ],
   "source": [
    "parameter_C = {'C':[0.1, 1, 10, 100, 1000]}\n",
    "svr = svm.SVR(kernel='linear', epsilon=1000)\n",
    "\n",
    "gridSearch = model_selection.GridSearchCV(svr,parameter_C, cv=5)\n",
    "gridSearch.fit(Xtrain_scaled, Ytrain)\n",
    "\n",
    "print(\"\\nLinear SVM\")\n",
    "print(\"Best value for hyperparameters: \",gridSearch.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TO DO - LEARN A MODEL WITH LINEAR KERNEL AND BEST CHOICE OF HYPERPARAMETERS\n",
    "\n",
    "This model will be compared with the best models with other kernels using validation (not cross validation).\n",
    "\n",
    "DO NOT PASS PARAMETERS BY HARD-CODING THEM IN THE CODE.\n",
    "\n",
    "Print the training score of the best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score:  0.6397700877886906\n"
     ]
    }
   ],
   "source": [
    "C_best_linear= gridSearch.best_params_['C']\n",
    "#print(\"C:\",C_best) \n",
    "best_model_linear = svm.SVR(kernel='linear', C=C_best_linear, epsilon=1000)\n",
    "best_model_linear.fit(Xtrain_scaled, Ytrain)\n",
    "score_linear = best_model_linear.score(Xtrain_scaled, Ytrain)\n",
    "\n",
    "print(\"Training score: \", score_linear)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TO DO - CHOOSE THE BEST HYPERPARAMETERS FOR POLY KERNEL\n",
    "\n",
    "Consider svm.SVR and polynomial kernel. Consider the following hyperparameters and their values:\n",
    "- C: 0.1, 1, 10, 100, 1000\n",
    "- degree: 2, 3, 4\n",
    "\n",
    "Leave all other input parameters to default. \n",
    "\n",
    "Find the best value of the hyperparameters using 5-fold cross validation. Use model_selection.GridSearchCV to perform the cross-validation.\n",
    "\n",
    "Print the best value of the hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Poly SVM\n",
      "Best value for hyperparameters:  {'C': 1000, 'degree': 3}\n"
     ]
    }
   ],
   "source": [
    "parameters = {'C':[0.1, 1, 10, 100, 1000], 'degree':[2, 3, 4]}\n",
    "              \n",
    "svr_poly = svm.SVR(kernel='poly',epsilon=1000)\n",
    "gridSearch_poly = model_selection.GridSearchCV(svr_poly,parameters,cv=5)\n",
    "gridSearch_poly.fit(Xtrain_scaled,Ytrain)\n",
    "\n",
    "print(\"\\nPoly SVM\")\n",
    "print(\"Best value for hyperparameters: \", gridSearch_poly.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## TO DO - LEARN A MODEL WITH POLY KERNEL AND BEST CHOICE OF HYPERPARAMETERS\n",
    "\n",
    "This model will be compared with the best models with other kernels using validation (not cross validation).\n",
    "\n",
    "DO NOT PASS PARAMETERS BY HARD-CODING THEM IN THE CODE.\n",
    "\n",
    "Print the training score of the best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score:  0.5612777885208244\n"
     ]
    }
   ],
   "source": [
    "C_best_poly = gridSearch_poly.best_params_['C']\n",
    "degree_best_poly = gridSearch_poly.best_params_['degree']\n",
    "\n",
    "best_model_poly = svm.SVR(kernel='poly',C=C_best_poly,degree=degree_best_poly,epsilon=1000)\n",
    "best_model_poly.fit(Xtrain_scaled,Ytrain)\n",
    "score_poly = best_model_poly.score(Xtrain_scaled,Ytrain)\n",
    "\n",
    "print(\"Training score: \", score_poly)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TO DO - CHOOSE THE BEST HYPERPARAMETERS FOR RBF KERNEL\n",
    "\n",
    "Consider svm.SVR and RBF kernel. Consider the following hyperparameters and their values:\n",
    "- C: 0.1, 1, 10, 100, 1000\n",
    "- gamma: 0.01\n",
    "\n",
    "Leave all other input parameters to default. \n",
    "\n",
    "Find the best value of the hyperparameters using 5-fold cross validation. Use model_selection.GridSearchCV to perform the cross-validation.\n",
    "\n",
    "Print the best value of the hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RBF SVM\n",
      "Best value for hyperparameters:  {'C': 1000, 'gamma': 0.01}\n"
     ]
    }
   ],
   "source": [
    "parameters_rbf = {'C':[0.1, 1, 10, 100, 1000], 'gamma':[0.01]}\n",
    "\n",
    "svr_rbf = svm.SVR(kernel='rbf',epsilon=1000)\n",
    "gridSearch_rbf = model_selection.GridSearchCV(svr_rbf,parameters_rbf,cv=5)\n",
    "gridSearch_rbf.fit(Xtrain_scaled,Ytrain)\n",
    "\n",
    "print(\"\\nRBF SVM\")\n",
    "print(\"Best value for hyperparameters: \", gridSearch_rbf.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TO DO - LEARN A MODEL WITH RBF KERNEL AND BEST CHOICE OF HYPERPARAMETERS\n",
    "\n",
    "This model will be compared with the best models with other kernels using validation (not cross validation).\n",
    "\n",
    "DO NOT PASS PARAMETERS BY HARD-CODING THEM IN THE CODE.\n",
    "\n",
    "Print the training score of the best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score:  0.12101760121263583\n"
     ]
    }
   ],
   "source": [
    "C_best_rbf = gridSearch_rbf.best_params_['C']\n",
    "gamma_best_rbf = gridSearch_rbf.best_params_['gamma']\n",
    "\n",
    "best_model_rbf = svm.SVR(kernel='rbf',C=C_best_rbf,gamma=gamma_best_rbf,epsilon=1000)\n",
    "best_model_rbf.fit(Xtrain_scaled,Ytrain)\n",
    "score_rbf = best_model_rbf.score(Xtrain_scaled,Ytrain)\n",
    "\n",
    "print(\"Training score: \", score_rbf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## TO DO - CHOOSE THE BEST HYPERPARAMETERS FOR SIGMOID KERNEL\n",
    "\n",
    "Consider svm.SVR and sigmoid kernel. Consider the following hyperparameters and their values:\n",
    "- C: 0.1, 1, 10, 100, 1000\n",
    "- gamma: 0.01\n",
    "- coef0: 0, 1\n",
    "\n",
    "Leave all other input parameters to default. \n",
    "\n",
    "Find the best value of the hyperparameters using 5-fold cross validation. Use model_selection.GridSearchCV to perform the cross-validation.\n",
    "\n",
    "Print the best value of the hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sigmoid SVM\n",
      "Best value for hyperparameters:  {'C': 1000, 'coef0': 0, 'gamma': 0.01}\n"
     ]
    }
   ],
   "source": [
    "parameters_sig = {'C':[0.1, 1, 10, 100, 1000], 'gamma':[0.01], 'coef0':[0,1]}\n",
    "\n",
    "svr_sig = svm.SVR(kernel='sigmoid',epsilon=1000)\n",
    "gridSearch_sig = model_selection.GridSearchCV(svr_sig,parameters_sig,cv=5)\n",
    "gridSearch_sig.fit(Xtrain_scaled,Ytrain)\n",
    "\n",
    "print(\"\\nSigmoid SVM\")\n",
    "print(\"Best value for hyperparameters: \", gridSearch_sig.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## TO DO - LEARN A MODEL WITH SIGMOID KERNEL AND BEST CHOICE OF HYPERPARAMETERS\n",
    "\n",
    "This model will be compared with the best models with other kernels using validation (not cross validation).\n",
    "\n",
    "DO NOT PASS PARAMETERS BY HARD-CODING THEM IN THE CODE.\n",
    "\n",
    "Print the training score of the best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score:  0.11515261586785563\n"
     ]
    }
   ],
   "source": [
    "C_best_sig = gridSearch_sig.best_params_['C']\n",
    "gamma_best_sig = gridSearch_sig.best_params_['gamma']\n",
    "coef0_best_sig = gridSearch_sig.best_params_['coef0']\n",
    "\n",
    "best_model_sig = svm.SVR(kernel='sigmoid',C=C_best_sig,gamma=gamma_best_sig,coef0=coef0_best_sig,epsilon=1000)\n",
    "best_model_sig.fit(Xtrain_scaled,Ytrain)\n",
    "score_sig = best_model_sig.score(Xtrain_scaled,Ytrain)\n",
    "\n",
    "print(\"Training score: \", score_sig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## TO DO - USE VALIDATION TO CHOOSE THE BEST MODEL AMONG THE ONES LEARNED FOR THE VARIOUS KERNELS\n",
    "\n",
    "Use validation to choose the best model among the four ones (one for each kernel) you have learned above.\n",
    "\n",
    "Print, following exactly the order described here, with 1 value for each line:\n",
    "- the validation score of SVM with linear kernel (the template below does not include such print)\n",
    "- the validation score of SVM with polynomial kernel (the template below does not include such print)\n",
    "- the validation score of SVM with rbf kernel (the template below does not include such print)\n",
    "- the validation score of SVM with sigmoid kernel (the template below does not include such print)\n",
    "- the best kernel (e.g., sigmoid) \n",
    "- the validation score of the best kernel \n",
    "\n",
    "For the first 4 prints, use the format: \"kernel validation score: \". For example, for linear kernel \"Linear validation score: \", for rbf \"rbf validation score: \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "VALIDATION TO CHOOSE SVM KERNEL\n",
      "linear validation score:  0.5905139730757103\n",
      "poly validation score:  0.3902725685208822\n",
      "rbf validation score:  0.12225458384488064\n",
      "sigmoid validation score:  0.11673452026233799\n",
      "Best kernel:  linear\n",
      "Validation score of best kernel:  0.5905139730757103\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nVALIDATION TO CHOOSE SVM KERNEL\")\n",
    "\n",
    "models = [best_model_linear,best_model_poly,best_model_rbf,best_model_sig]\n",
    "best_score = 0\n",
    "best_model = svm.SVR()\n",
    "\n",
    "for model in models:\n",
    "    score = model.score(Xval_scaled,Yval)\n",
    "    print(model.get_params()['kernel'], \"validation score: \", score )\n",
    "    if score > best_score:\n",
    "        best_score = score\n",
    "        best_model = model\n",
    "\n",
    "print(\"Best kernel: \", best_model.get_params()['kernel'])\n",
    "print(\"Validation score of best kernel: \", best_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TO DO - LEARN THE FINAL MODEL FOR WHICH YOU WANT TO ESTIMATE THE GENERALIZATION ERROR\n",
    "\n",
    "Learn the final model (i.e., the one you would use to make predictions about future data).\n",
    "\n",
    "Print the score of the model on the data used to learn it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TRAINING SCORE BEST MODEL\n",
      "Score of the best model on the data used to learn it:  0.6276647451725295\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nTRAINING SCORE BEST MODEL\")\n",
    "final_model = svm.SVR(**best_model.get_params())\n",
    "final_model.fit(Xtrain_val_scaled,Ytrain_val)\n",
    "\n",
    "final_score = final_model.score(Xtrain_val_scaled,Ytrain_val)\n",
    "print(\"Score of the best model on the data used to learn it: \", final_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## TO DO - PRINT THE ESTIMATE  OF THE GENERALIZATION ERROR FOR THE FINAL MODEL\n",
    "\n",
    "Print the estimate of the generalization \"score\" for the final model. The generalization \"score\" is the score computed on the data used to estimate the generalization error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "GENERALIZATION SCORE BEST MODEL\n",
      "Estimate of the generalization score for best SVM model:  0.6271892242280019\n"
     ]
    }
   ],
   "source": [
    "generalization_score = final_model.score(Xtest_scaled,Ytest)\n",
    "\n",
    "print(\"\\nGENERALIZATION SCORE BEST MODEL\")\n",
    "print(\"Estimate of the generalization score for best SVM model: \",generalization_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## TO DO - ANSWER THE FOLLOWING\n",
    "\n",
    "Print the training score (score on data used to train the model) and the generalization score (score on data used to estimate the generalization error) of the final SVM model THAT YOU OBTAIN WHEN YOU RUN THE CODE, one per line, printing the smallest one first. NOTE: THE VALUES HERE SHOULD BE HARDCODED\n",
    "\n",
    "Print you answer (yes/no) to the following question: does the relation (i.e., smaller, larger) between the training score and the generalization score agree with the theory?\n",
    "\n",
    "Print your motivation for the yes/no answer above, using at most 500 characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ANSWER\n",
      "Generalization score:  0.6271892242280019\n",
      "Training score:  0.6276647451725295\n",
      "Yes.\n",
      "My training score is higher than my generalization score, from theory I know that it is normal if the training value is higher than the test value. \n",
      "This is because my model uses the training data to make predictions, so it’s expected to perform slightly better on the training data.\n",
      "This difference, however, must be as small as possible; in my case is equal to 0.0004755209445275188.\n",
      "When the training score is much higher than the generalization score, it means that overfitting has occurred.\n",
      "Therefore, I am satisfied with the score obtained\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nANSWER\")\n",
    "\n",
    "train_score = 0.6276647451725295\n",
    "gen_score = 0.6271892242280019 \n",
    "\n",
    "\n",
    "#note that you may have to invert the order of the following 2 lines, print the smallest 1 first. THE VALUES HERE SHOULD BE HARD CODED!\n",
    "print(\"Generalization score: \",gen_score)\n",
    "print(\"Training score: \", train_score)\n",
    "\n",
    "#the following is a string with you anwer\n",
    "motivation = \"Yes.\\nMy training score is higher than my generalization score, from theory I know that it is normal if the training value is higher than the test value. \\nThis is because my model uses the training data to make predictions, so it’s expected to perform slightly better on the training data.\\nThis difference, however, must be as small as possible; in my case is equal to 0.0004755209445275188.\\nWhen the training score is much higher than the generalization score, it means that overfitting has occurred.\\nTherefore, I am satisfied with the score obtained\"\n",
    "\n",
    "print(motivation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## TO DO: LEARN A STANDARD LINEAR MODEL\n",
    "Learn a standard linear model using scikit learn.\n",
    "\n",
    "Print the score of the model on the data used to learn it.\n",
    "\n",
    "Print the generalization \"score\" of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LR MODEL\n",
      "Score of LR model on data used to learng it:  0.7062874991650314\n",
      "Generalization score of LR model:  0.746048866078462\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nLR MODEL\")\n",
    "\n",
    "standard_linear_model = linear_model.LinearRegression()\n",
    "standard_linear_model.fit(Xtrain_val_scaled,Ytrain_val)\n",
    "\n",
    "score_linear = standard_linear_model.score(Xtrain_val_scaled,Ytrain_val)\n",
    "score_linear_gen = standard_linear_model.score(Xtest_scaled,Ytest)\n",
    "\n",
    "print(\"Score of LR model on data used to learng it: \", score_linear)\n",
    "print(\"Generalization score of LR model: \", score_linear_gen)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
